{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dotZjUvecRI8",
    "outputId": "a7869b66-c61a-439e-86b3-110bd10f4b0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.7.0\n",
      "Hub version:  0.12.0\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bert\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import  Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow Version:\",tf.__version__)\n",
    "print(\"Hub version: \",hub.__version__)\n",
    "pd.set_option('display.max_colwidth',1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uH1zw2Pa13m"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/dataset/4af304c0f797e3b08f22895d6a0dcf95eee4c37f7a20775c7a4ee2281c6ba2ff\n",
    "DATASET_PATH = \"NoThemeTweets.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv( \n",
    "         DATASET_PATH,\n",
    "         engine=\"python\", \n",
    "         encoding=\"latin1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1031761728445530112</td>\n",
       "      <td>@Tixaa23 14 para eu ir :)</td>\n",
       "      <td>Tue Aug 21 04:35:39 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1031761040462278656</td>\n",
       "      <td>@drexalvarez O meu like eu jÃ¡ dei na Ã©poca :)</td>\n",
       "      <td>Tue Aug 21 04:32:55 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1031760962372689920</td>\n",
       "      <td>Eu sÃ³ queria conseguir comer alguma coisa pra poder dormir :)</td>\n",
       "      <td>Tue Aug 21 04:32:37 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1031760948250456066</td>\n",
       "      <td>:D que lindo dia !</td>\n",
       "      <td>Tue Aug 21 04:32:33 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1031760895985246208</td>\n",
       "      <td>@Primo_Resmungao Pq da pr jeito!!Ã© uma \"oferta\", ha q aproveitar. :P</td>\n",
       "      <td>Tue Aug 21 04:32:21 +0000 2018</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  \\\n",
       "0  1031761728445530112   \n",
       "1  1031761040462278656   \n",
       "2  1031760962372689920   \n",
       "3  1031760948250456066   \n",
       "4  1031760895985246208   \n",
       "\n",
       "                                                              tweet_text  \\\n",
       "0                                              @Tixaa23 14 para eu ir :)   \n",
       "1                        @drexalvarez O meu like eu jÃ¡ dei na Ã©poca :)   \n",
       "2         Eu sÃ³ queria conseguir comer alguma coisa pra poder dormir :)   \n",
       "3                                                     :D que lindo dia !   \n",
       "4  @Primo_Resmungao Pq da pr jeito!!Ã© uma \"oferta\", ha q aproveitar. :P   \n",
       "\n",
       "                       tweet_date sentiment query_used  \n",
       "0  Tue Aug 21 04:35:39 +0000 2018  Positivo         :)  \n",
       "1  Tue Aug 21 04:32:55 +0000 2018  Positivo         :)  \n",
       "2  Tue Aug 21 04:32:37 +0000 2018  Positivo         :)  \n",
       "3  Tue Aug 21 04:32:33 +0000 2018  Positivo         :)  \n",
       "4  Tue Aug 21 04:32:21 +0000 2018  Positivo         :)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset[[\"tweet_text\", \"sentiment\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text    0\n",
       "sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Tixaa23 14 para eu ir :)</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@drexalvarez O meu like eu jÃ¡ dei na Ã©poca :)</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eu sÃ³ queria conseguir comer alguma coisa pra poder dormir :)</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:D que lindo dia !</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Primo_Resmungao Pq da pr jeito!!Ã© uma \"oferta\", ha q aproveitar. :P</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              tweet_text  \\\n",
       "0                                              @Tixaa23 14 para eu ir :)   \n",
       "1                        @drexalvarez O meu like eu jÃ¡ dei na Ã©poca :)   \n",
       "2         Eu sÃ³ queria conseguir comer alguma coisa pra poder dormir :)   \n",
       "3                                                     :D que lindo dia !   \n",
       "4  @Primo_Resmungao Pq da pr jeito!!Ã© uma \"oferta\", ha q aproveitar. :P   \n",
       "\n",
       "  sentiment  \n",
       "0  Positivo  \n",
       "1  Positivo  \n",
       "2  Positivo  \n",
       "3  Positivo  \n",
       "4  Positivo  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    # Not needed to be imported globally\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    text = BeautifulSoup(text, \"lxml\").get_text()\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE) # Remove urls\n",
    "    text = re.sub(r\"@[A-Za-z0-9]+\", ' ', text)\n",
    "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
    "    text = re.sub(r\"[^a-zA-Z.!?']\", ' ', text)\n",
    "    text = re.sub(r\" +\", ' ', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tweet_text\"] = df[\"tweet_text\"].apply(lambda text: preprocess_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"tweet_text\":\"text\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134780</th>\n",
       "      <td>EU to com muita dor de cabe a j tomei rem dio e n o mudou nada aaaa eu preciso estudar mas n o consigo</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404943</th>\n",
       "      <td>faz mais de um m s que eu n o vejo a mel</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273057</th>\n",
       "      <td>called me foda isso mesmo.. meu pai que advogado.. tem processo que ta a fcking anos demorando...se fosse rapida essa justi a tudo seria melhor x e o pior que eu pago imposto e os cara parece que n o trabalha D</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617541</th>\n",
       "      <td>tamb m</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601454</th>\n",
       "      <td>Eu tamb m</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                       text  \\\n",
       "134780                                                                                                              EU to com muita dor de cabe a j tomei rem dio e n o mudou nada aaaa eu preciso estudar mas n o consigo    \n",
       "404943                                                                                                                                                                            faz mais de um m s que eu n o vejo a mel    \n",
       "273057   called me foda isso mesmo.. meu pai que advogado.. tem processo que ta a fcking anos demorando...se fosse rapida essa justi a tudo seria melhor x e o pior que eu pago imposto e os cara parece que n o trabalha D   \n",
       "617541                                                                                                                                                                                                              tamb m    \n",
       "601454                                                                                                                                                                                                           Eu tamb m    \n",
       "\n",
       "       sentiment  \n",
       "134780  Negativo  \n",
       "404943  Negativo  \n",
       "273057  Positivo  \n",
       "617541  Negativo  \n",
       "601454  Positivo  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading clean data directly\n",
    "df = pd.read_csv(\"data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "5GbNMjbS_b8J",
    "outputId": "121fb657-1e3d-4095-c356-d209c263b4a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negativo    522707\n",
       "Positivo    263107\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the dataset\n",
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RTsrFxRWcOE1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negativo    0.665179\n",
       "Positivo    0.334821\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Gbcp65zz_7wk",
    "outputId": "5eba1187-277d-44b8-9c5c-2951b20bb596"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df : (785814, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of df : {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "h_uP_hOAR_ac",
    "outputId": "e19ced59-0b1b-4431-f4e8-49ae6600c538"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         545\n",
       "sentiment      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785269, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IE7HnvcfXiUY"
   },
   "source": [
    "**Download token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rs4wDf4QOwWe",
    "outputId": "13fdeba6-421d-4652-b266-0f26bf588104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-15 00:28:42--  https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\n",
      "Resolving neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)... 52.219.109.42\n",
      "Connecting to neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)|52.219.109.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 406220891 (387M) [application/zip]\n",
      "Saving to: ‘bert-base-portuguese-cased_pytorch_checkpoint.zip.1’\n",
      "\n",
      "bert-base-portugues 100%[===================>] 387,40M  12,5MB/s    in 31s     \n",
      "\n",
      "2022-02-15 00:29:14 (12,4 MB/s) - ‘bert-base-portuguese-cased_pytorch_checkpoint.zip.1’ saved [406220891/406220891]\n",
      "\n",
      "--2022-02-15 00:29:14--  https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/vocab.txt\n",
      "Resolving neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)... 52.219.88.160\n",
      "Connecting to neuralmind-ai.s3.us-east-2.amazonaws.com (neuralmind-ai.s3.us-east-2.amazonaws.com)|52.219.88.160|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 209528 (205K) [text/plain]\n",
      "Saving to: ‘vocab.txt’\n",
      "\n",
      "vocab.txt           100%[===================>] 204,62K   579KB/s    in 0,4s    \n",
      "\n",
      "2022-02-15 00:29:15 (579 KB/s) - ‘vocab.txt’ saved [209528/209528]\n",
      "\n",
      "Archive:  bert-base-portuguese-cased_pytorch_checkpoint.zip\n",
      "  inflating: bert-base-portuguese-cased/config.json  \n",
      "  inflating: bert-base-portuguese-cased/pytorch_model.bin  \n"
     ]
    }
   ],
   "source": [
    "!rm -rf bert-base-portuguese-cased\n",
    "!mkdir bert-base-portuguese-cased\n",
    "!wget https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\n",
    "!wget https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/vocab.txt \n",
    "\n",
    "\n",
    "!unzip bert-base-portuguese-cased_pytorch_checkpoint.zip -d bert-base-portuguese-cased\n",
    "!mv vocab.txt bert-base-portuguese-cased/vocab.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "UAQ1jHpmXoId",
    "outputId": "91f25992-b18c-43b4-eeb5-e21788d79207"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 01:19:04.564751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-15 01:19:04.619988: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-02-15 01:19:04.628474: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-02-15 01:19:04.628499: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-02-15 01:19:04.629198: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertConfig, TFBertModel\n",
    "bert_model = TFBertModel.from_pretrained(\"bert-base-portuguese-cased\", from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESyS2xsQbQlm"
   },
   "outputs": [],
   "source": [
    "# Functions for constructing BERT Embeddings: input_ids, input_masks, input_segments and Inputs\n",
    "MAX_SEQ_LEN=250 # max sequence length\n",
    "\n",
    "def get_masks(tokens):\n",
    "    \"\"\"Masks: 1 for real tokens and 0 for paddings\"\"\"\n",
    "    return [1]*len(tokens) + [0] * (MAX_SEQ_LEN - len(tokens))\n",
    " \n",
    "def get_segments(tokens):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"  \n",
    "    segments = []\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            current_segment_id = 1\n",
    "    return segments + [0] * (MAX_SEQ_LEN - len(tokens))\n",
    "\n",
    "def get_ids(tokens, tokenizer):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens,)\n",
    "    input_ids = token_ids + [0] * (MAX_SEQ_LEN - len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def create_single_input(sentence, tokenizer, max_len):\n",
    "    \"\"\"Create an input from a sentence\"\"\"\n",
    "    stokens = tokenizer.tokenize(sentence)\n",
    "    stokens = stokens[:max_len]\n",
    "    stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
    " \n",
    "    ids = get_ids(stokens, tokenizer)\n",
    "    masks = get_masks(stokens)\n",
    "    segments = get_segments(stokens)\n",
    "\n",
    "    return ids, masks, segments\n",
    " \n",
    "def convert_sentences_to_features(sentences, tokenizer):\n",
    "    \"\"\"Convert sentences to features: input_ids, input_masks and input_segments\"\"\"\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    " \n",
    "    for sentence in tqdm(sentences,position=0, leave=True):\n",
    "        ids,masks,segments=create_single_input(sentence,tokenizer,MAX_SEQ_LEN-2)\n",
    "        assert len(ids) == MAX_SEQ_LEN\n",
    "        assert len(masks) == MAX_SEQ_LEN\n",
    "        assert len(segments) == MAX_SEQ_LEN\n",
    "        input_ids.append(ids)\n",
    "        input_masks.append(masks)\n",
    "        input_segments.append(segments)\n",
    "\n",
    "    return [np.asarray(input_ids, dtype=np.int32), \n",
    "        np.asarray(input_masks, dtype=np.int32), \n",
    "        np.asarray(input_segments, dtype=np.int32)]\n",
    "\n",
    "def create_tonkenizer(bert_layer):\n",
    "    \"\"\"Instantiate Tokenizer with vocab\"\"\"\n",
    "    # vocab_file=bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    # do_lower_case=bert_layer.resolved_object.do_lower_case.numpy() \n",
    "    # tokenizer=bert.bert_tokenization.FullTokenizer(vocab_file,do_lower_case)\n",
    "    do_lower_case = False\n",
    "    tokenizer = BertTokenizer(\"bert-base-portuguese-cased/vocab.txt\", do_lower_case)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xs6_p8VTgpoy"
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_mFZ2HRcRJB"
   },
   "outputs": [],
   "source": [
    "def nlp_model(callable_object):\n",
    "    # Load the pre-trained BERT base model\n",
    "    bert_layer = hub.KerasLayer(handle=callable_object, trainable=True)  \n",
    "\n",
    "\n",
    "    #bert_layer = callable_object\n",
    "   \n",
    "    # BERT layer three inputs: ids, masks and segments\n",
    "    input_ids = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name=\"input_ids\")           \n",
    "    input_masks = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name=\"input_masks\")       \n",
    "    input_segments = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    \n",
    "    inputs = [input_ids, input_masks, input_segments] # BERT inputs\n",
    "    # If using hub.KerasLayer, PLEASE, CHANGE THE ORDER of the variables, I mean: \n",
    "    #pooled_output, sequence_output = bert_layer(inputs)\n",
    "    #sequence_output, pooled_output = bert_layer(inputs) # BERT outputs \n",
    "    \n",
    "    bert_output = bert_model(inputs)\n",
    "    sequence_output = bert_output.last_hidden_state\n",
    "    pooled_output = bert_output.pooler_output\n",
    "    \n",
    "    print(pooled_output)\n",
    "    # Add a hidden layer\n",
    "    x = Dense(units=768, activation='relu')(pooled_output)\n",
    "    x = Dropout(0.3)(x)\n",
    " \n",
    "    # Add output layer\n",
    "    outputs = Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "    # Construct a new model\n",
    "    model = Model(inputs=inputs, outputs=outputs, )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "iPQ-WWSidREI",
    "outputId": "954d23fd-6b6b-4246-df25-b12bb0ae80a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/pooler/dense/Tanh:0', description=\"created by layer 'tf_bert_model'\")\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " input_masks (InputLayer)       [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)       [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108923136   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'input_masks[0][0]',            \n",
      "                                tentions(last_hidde               'segment_ids[0][0]']            \n",
      "                                n_state=(None, 500,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 768)          590592      ['tf_bert_model[1][1]']          \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 768)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 3)            2307        ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,516,035\n",
      "Trainable params: 109,516,035\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = nlp_model(bert_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ViqJURL5qcZJ"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_num\"] = df[\"sentiment\"].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU to com muita dor de cabe a j tomei rem dio e n o mudou nada aaaa eu preciso estudar mas n o consigo</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>faz mais de um m s que eu n o vejo a mel</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>called me foda isso mesmo.. meu pai que advogado.. tem processo que ta a fcking anos demorando...se fosse rapida essa justi a tudo seria melhor x e o pior que eu pago imposto e os cara parece que n o trabalha D</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tamb m</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eu tamb m</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                  text  \\\n",
       "0                                                                                                              EU to com muita dor de cabe a j tomei rem dio e n o mudou nada aaaa eu preciso estudar mas n o consigo    \n",
       "1                                                                                                                                                                            faz mais de um m s que eu n o vejo a mel    \n",
       "2   called me foda isso mesmo.. meu pai que advogado.. tem processo que ta a fcking anos demorando...se fosse rapida essa justi a tudo seria melhor x e o pior que eu pago imposto e os cara parece que n o trabalha D   \n",
       "3                                                                                                                                                                                                              tamb m    \n",
       "4                                                                                                                                                                                                           Eu tamb m    \n",
       "\n",
       "  sentiment  sentiment_num  \n",
       "0  Negativo              0  \n",
       "1  Negativo              0  \n",
       "2  Positivo              1  \n",
       "3  Negativo              0  \n",
       "4  Positivo              1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "XL5LaS68Qo8G",
    "outputId": "6463c6df-d1be-4394-8d0e-dc817e649e64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x_train: (549688,); \tX_test: (235581,)\n",
      "\n",
      "y_test: \n",
      "0    0.665397\n",
      "1    0.334603\n",
      "Name: sentiment_num, dtype: float64, \n",
      "\n",
      "y_train: \n",
      "0    0.665397\n",
      "1    0.334603\n",
      "Name: sentiment_num, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████▉| 549417/549688 [02:50<00:00, 3516.83it/s]"
     ]
    }
   ],
   "source": [
    "# Create examples for training and testing\n",
    "\n",
    "df = df.sample(frac=1) # Shuffle the dataset\n",
    "tokenizer = create_tonkenizer(model.layers[3])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['sentiment_num'], \n",
    "    test_size=0.3, \n",
    "    stratify=df['sentiment_num'], \n",
    "    random_state=15 \n",
    "    )\n",
    "\n",
    "print( \"\\nx_train: {}; \\tX_test: {}\".format(X_train.shape, X_test.shape))\n",
    "print(\"\\ny_test: \\n{}, \\n\\ny_train: \\n{}\".format(y_train.value_counts(normalize=True), y_test.value_counts(normalize=True) ) )\n",
    "\n",
    "X_train = convert_sentences_to_features(X_train, tokenizer)\n",
    "X_test = convert_sentences_to_features(X_test, tokenizer)\n",
    "\n",
    "y_train = to_categorical( y_train )\n",
    "y_test =  to_categorical( y_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "t8CAhbzjnk8M",
    "outputId": "7a6c5c66-9609-43fe-b2cc-af6ee1fe6066"
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYv9EW9O0rHl"
   },
   "outputs": [],
   "source": [
    "# callback\n",
    "\n",
    "checkpoint_path = \"./sentiment_analysis_model\"\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ckpt_manager.save()\n",
    "        print(\"Checkpoint saved at {}.\".format(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "IzSF2HJi5XsY",
    "outputId": "583cfb79-0c49-4f3a-c130-a58cd5118298"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 2\n",
    "\n",
    "# Use Adam optimizer to minimize the categorical_crossentropy loss\n",
    "opt = Adam(learning_rate=2e-5)\n",
    "\n",
    "# loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "# metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "\n",
    "# softmax_cross_entropy_with_logits\n",
    "model.compile(optimizer=opt, \n",
    "              loss= 'categorical_crossentropy', #binary_crossentropy\n",
    "              metrics = ['categorical_accuracy']\n",
    "              )\n",
    "\n",
    "# Fit the data to the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    verbose = 1,\n",
    "                    callbacks=[CustomCallback()]\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_zmw_IyL1172"
   },
   "outputs": [],
   "source": [
    "def save_model(model, name, path, h5=False):\n",
    "    '''\n",
    "    model, model_name, path, h5(optional)\n",
    "    '''\n",
    "    \n",
    "    if h5:\n",
    "        model.save( \"{}.h5\".format(name) )\n",
    "    else:\n",
    "        model.save( name )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "k4tg3sFSMRv6",
    "outputId": "05f2e467-4937-418f-abf8-aa856c9cd966"
   },
   "outputs": [],
   "source": [
    "save_model(model, \"sentiment_model\", \"trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QmwK7C4-re9I",
    "outputId": "d7f58567-17a1-4063-857d-0295aebab217"
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "toHq_3_Am6if"
   },
   "source": [
    "## Analysis of model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCqF3D54iGiZ"
   },
   "outputs": [],
   "source": [
    "# Predict on test dataset\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "pred_test = np.argmax(model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "6pcfuN3wvFJV",
    "outputId": "8bb0c103-cccc-47b7-99bc-5d6b6c8a11b7"
   },
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(y_test,axis=1), pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "ZxyAqz094Lzv",
    "outputId": "74ae77a2-9e3a-4b17-b77a-433d6fb658e7"
   },
   "outputs": [],
   "source": [
    "print(pred_test[:40])\n",
    "print( y_test[:40].argmax(1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iA653kqqM5bk"
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-tvup1vj-mj"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model_, sentence):\n",
    "    sent = []\n",
    "    sent.append(sentence)\n",
    "    sentence_feature = convert_sentences_to_features(sent, tokenizer)\n",
    "\n",
    "    prediction = np.argmax(model_.predict( sentence_feature ) , axis=1) \n",
    "\n",
    "    # Show Positivo/Negativo\n",
    "    pred = [\"Negativo\" if x == 0 else \"Positivo\" if x == 2 else \"Neutro\"  for x in prediction]\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "uR4x04shSszC",
    "outputId": "818812de-04a6-4c20-9c74-3df71ad4bb36"
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "get_predictions( model, \"Aquele ator é ruim\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "xaVD-Upun0Pd",
    "outputId": "0dec13bc-e38c-4c26-aa07-ae7cefa2b229"
   },
   "outputs": [],
   "source": [
    "get_predictions( model, \"Eu gosto do seu sorriso\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "TensorFlow2_BERT_Sentiment_Analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
